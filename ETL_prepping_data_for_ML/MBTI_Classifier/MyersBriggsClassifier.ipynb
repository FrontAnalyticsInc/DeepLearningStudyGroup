{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Myers-Briggs Personality Type Classifier\n",
    "### The Project:\n",
    "Create a model that predicts a someone's MBTI personality type using their online posts as input.\n",
    "\n",
    "### The Data:\n",
    "This dataset is from Kaggle.com and contains text data in the form of the 50 most recent online posts to PersonalityCafe.com by over 8,000 users. Since Personality Cafe is a website that focuses on personality type models (especially MBTI), there are multiple instances in posts where the user's personality type is mentioned. In my previous version of this notebook I left all mentions of personality in the text. However, in this version posts such as \"That's so INTJ, bro!\" have been filtered to \"That's so bro!\" (Since we are using a bag-of-words model here it won't matter that the revised sentence doesn't make much sense).\n",
    "Here is the full dataset url: https://www.kaggle.com/datasnaek/mbti-type/data\n",
    "\n",
    "### The Model\n",
    "Earlier, I trained a classifier to predict which type out of the 16 possible MBTI personality types belongs to a person based on their last 50 online posts. The accuracy is about 27% for this holistic model with all 16 labels. Although this sounds like pretty bad accuracy when you consider that if we were to pick one personality type at random as a guess that would give us 6.25% accuracy. So we are doing quite a bit better than that.\n",
    "However, what I want to do here is create four separate classifiers and output a prediction for each one. Breaking this up should provide some interesting insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I still include the 16-way classifier as I had in the previous notebook. However, here I also break the single 16-way classifier into 4 separate two-way classifiers. So we are training five classifiers in all:\n",
    "* The all-in classifier that predicts which of the 16 personality types the text belongs to\n",
    "* Dichotomy 1, E or I. Favorite world dichotomy, is this person extroverted or introverted?\n",
    "* Dichotomy 2, N or S. Information dichotomy, does this person attach meaning to the information they consume (iNtuitive) or do they take information as is (sensing)?\n",
    "* Dichotomy 3, F or T. Descisions dichotomy, does this person favor feelings of others and themselves when making decisions or do they operate more logically and consistently?\n",
    "* Dichotomy 4, J or P. Structure dichotomy, does this person have things figured out already or are they open to new information?\n",
    "\n",
    "Breaking down into dichotomies significantly improves the accuracy of the classifiers. See the results at the Vectorize Train and Evaluate section for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from nltk import word_tokenize\n",
    "import re\n",
    "\n",
    "# Classifiers to use in this notebook\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vectorizer = DictVectorizer(sparse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Parameters for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joeydemple/.conda/envs/speech_processing/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:84: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Classifiers to be fitted and evaluated\n",
    "classifiers = [MultinomialNB(), \n",
    "               LogisticRegression(), \n",
    "               # svm.SVC(kernel='rbf'), \n",
    "               Perceptron(), \n",
    "               tree.DecisionTreeClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ratio of train/test data\n",
    "split_ratio = 0.85\n",
    "\n",
    "# seed for random split of train/test data\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Location of data\n",
    "file = './data/mbti_1.csv'\n",
    "\n",
    "# Our data is the MBTI-Type dataset from Kaggle.com\n",
    "# https://www.kaggle.com/datasnaek/mbti-type/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load set of words to filter from the text\n",
    "with open('./data/personality_words.txt', 'r') as reader:\n",
    "    personality_words = reader.read().split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Our Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_and_extract(filepath, split_ratio=0.85, seed=1):\n",
    "    loaded = pd.read_csv(filepath)\n",
    "    # print('Dataset size', loaded.shape, loaded.info)\n",
    "    # split into training, testing\n",
    "    train=loaded.sample(frac=split_ratio, random_state=seed)\n",
    "    test=loaded.drop(train.index)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_into_dichotomies(df):\n",
    "    # split ENTP or other personality type into four columns\n",
    "    df['dicho1'] = df.type.str[0]\n",
    "    df['dicho2'] = df.type.str[1]\n",
    "    df['dicho3'] = df.type.str[2]\n",
    "    df['dicho4'] = df.type.str[3]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_double_period(clean_str):\n",
    "    return clean_str.replace('..', '. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_delim(clean_str):\n",
    "    return clean_str.replace('|||', '. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_links(clean_str):\n",
    "    urlpattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    return re.sub(urlpattern, '*LINK*', clean_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_posts(posts_raw):\n",
    "    bow = []\n",
    "    if posts_raw.startswith('\"') or posts_raw.startswith(\"'\"):\n",
    "                # remove extra string quotes if exist\n",
    "        clean = posts_raw[1:-1]\n",
    "    else:\n",
    "        clean = posts_raw\n",
    "    clean = remove_double_period(clean)\n",
    "    clean = remove_delim(clean)\n",
    "    clean = replace_links(clean)\n",
    "    clean = word_tokenize(clean)\n",
    "    return [c.lower() for c in clean if c.lower() not in personality_words]  # filter personality words\n",
    "    # return [c.lower() for c in clean]  # not filtering personality words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vocab(df):\n",
    "    ## get vocabulary for a dataset, i.e. all possbile features\n",
    "    vocab = []\n",
    "    for row in df.itertuples():\n",
    "        vocab.extend(row.post_list)\n",
    "    return set(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_one(x, vocab, dichotomy=False):\n",
    "    # take one training example (dataframe row) and return a sparse feature vector\n",
    "    # init feature vec with zeros\n",
    "    feature_dict = {}\n",
    "    count_keys = len(feature_dict.keys())\n",
    "    \n",
    "    # I know this part is really not elegant code. Rewriting these functions from\n",
    "    # scratch would be the next step I take.\n",
    "    if dichotomy == 1:  # if personality type is split into dichotomies\n",
    "        label = x.dicho1\n",
    "    elif dichotomy == 2:  # if personality type is split into dichotomies\n",
    "        label = x.dicho2\n",
    "    elif dichotomy == 3:  # if personality type is split into dichotomies\n",
    "        label = x.dicho3\n",
    "    elif dichotomy == 4:  # if personality type is split into dichotomies\n",
    "        label = x.dicho4\n",
    "    else:          # if personality type is not split e.g. INTJ\n",
    "        label = x.type\n",
    "    \n",
    "    raw_feat = x.post_list\n",
    "    for fx in x.post_list:\n",
    "        if fx in vocab:\n",
    "            feature_dict[fx] = 1  # One Hot Encoding\n",
    "    return label, feature_dict  # returns label and feature dict for a single training sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature_dict(df, vocab, dichotomy=False):\n",
    "    # Create a feature dictionary for a dataset\n",
    "    X = []\n",
    "    y = []\n",
    "    for row in df.itertuples():\n",
    "        if dichotomy:\n",
    "            result = vectorize_one(row, vocab, dichotomy)\n",
    "        else:\n",
    "            result = vectorize_one(row, vocab)\n",
    "        y.append(result[0])\n",
    "        X.append(result[1])\n",
    "    return y, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_all(train, test, dichotomy=False):\n",
    "    vocab = get_vocab(train)\n",
    "    \n",
    "    if dichotomy:\n",
    "        # training data\n",
    "        y_train, X_train_dict = get_feature_dict(train, vocab, dichotomy)\n",
    "        X_train = vectorizer.fit_transform(X_train_dict)\n",
    "    \n",
    "        # testing data\n",
    "        y_test, X_test_dict = get_feature_dict(test, vocab, dichotomy)\n",
    "        X_test = vectorizer.transform(X_test_dict)\n",
    "    \n",
    "    else:\n",
    "        # training data\n",
    "        y_train, X_train_dict = get_feature_dict(train, vocab)\n",
    "        X_train = vectorizer.fit_transform(X_train_dict)\n",
    "    \n",
    "        # testing data\n",
    "        y_test, X_test_dict = get_feature_dict(test, vocab)\n",
    "        X_test = vectorizer.transform(X_test_dict)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_and_evaluate_one(classifier, X_train, y_train, X_test, y_test):\n",
    "    # fitting\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # accuracy\n",
    "    results = {}\n",
    "    y_hat_train = classifier.predict(X_train)\n",
    "    accur_train = sum(y_hat_train == y_train) / len(y_train)  # train accuracy\n",
    "    y_hat_test = classifier.predict(X_test)\n",
    "    accur_test = sum(y_hat_test == y_test) / len(y_test)  # test accuracy\n",
    "    results['accur_train'] = accur_train\n",
    "    results['accur_test'] = accur_test\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_and_evaluate_all(classifiers, X_train, y_train, X_test, y_test):\n",
    "    results = {}\n",
    "    for c in classifiers:\n",
    "        cname = str(c).split('(')[0]\n",
    "        print('Training '+cname+ '...')\n",
    "        results[cname] = fit_and_evaluate_one(c, X_train, y_train, X_test, y_test)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = load_and_extract(file, split_ratio, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Personality Types, i.e. all possible labels in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Personality_dichotomies = {1:{'E':0, 'I':0},\n",
    "#                            2:{'N':0, 'S':0},\n",
    "#                            3:{'F':0, 'T':0},\n",
    "#                            4:{'J':0, 'P':0}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split type into four dichotomies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = split_into_dichotomies(train)\n",
    "test = split_into_dichotomies(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rid of extra string quotes and tokenize into posts for each row in posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['post_list'] = train['posts'].apply(clean_posts)\n",
    "test['post_list'] = test['posts'].apply(clean_posts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Train and Evaluate\n",
    "I put all of these steps into one so that each model would run one at a time and overwrite the previous feature vectors. This should prevent using too much memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holistic Model<br>\n",
    "16 types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = vectorize_all(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultinomialNB...\n",
      "Training LogisticRegression...\n",
      "Training Perceptron...\n",
      "Training DecisionTreeClassifier...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accur_test</th>\n",
       "      <th>accur_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.382014</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.363566</td>\n",
       "      <td>0.985625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.264412</td>\n",
       "      <td>0.614999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.167563</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        accur_test  accur_train\n",
       "LogisticRegression        0.382014     1.000000\n",
       "Perceptron                0.363566     0.985625\n",
       "MultinomialNB             0.264412     0.614999\n",
       "DecisionTreeClassifier    0.167563     1.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holistic_result_dict = fit_and_evaluate_all(classifiers, X_train, y_train, X_test, y_test)\n",
    "holistic_result = pd.DataFrame.from_dict(holistic_result_dict).transpose().sort_values('accur_test', ascending=False)\n",
    "holistic_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best accuracy is about 38% for the holistic model with all 16 labels (using Logistic Regression and filtering out personality type terms). Although this sounds like pretty bad accuracy when you consider that if we were to pick one personality type at random as a guess that would give us 6.25% accuracy. So we are doing quite a bit better than that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dichotomized Model<br>\n",
    "First Dichotomy: E or I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultinomialNB...\n",
      "Training LogisticRegression...\n",
      "Training Perceptron...\n",
      "Training DecisionTreeClassifier...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accur_test</th>\n",
       "      <th>accur_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.790161</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.790161</td>\n",
       "      <td>0.895172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.770177</td>\n",
       "      <td>0.981557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.689470</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        accur_test  accur_train\n",
       "LogisticRegression        0.790161     1.000000\n",
       "MultinomialNB             0.790161     0.895172\n",
       "Perceptron                0.770177     0.981557\n",
       "DecisionTreeClassifier    0.689470     1.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = vectorize_all(train, test, dichotomy=1)\n",
    "dicho1_result_dict = fit_and_evaluate_all(classifiers, X_train, y_train, X_test, y_test)\n",
    "dicho1_result = pd.DataFrame.from_dict(dicho1_result_dict).transpose().sort_values('accur_test', ascending=False)\n",
    "dicho1_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second Dichotomy: N or S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultinomialNB...\n",
      "Training LogisticRegression...\n",
      "Training Perceptron...\n",
      "Training DecisionTreeClassifier...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accur_test</th>\n",
       "      <th>accur_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.840123</td>\n",
       "      <td>0.889070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.833974</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.787855</td>\n",
       "      <td>0.968131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.786318</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        accur_test  accur_train\n",
       "MultinomialNB             0.840123     0.889070\n",
       "LogisticRegression        0.833974     1.000000\n",
       "Perceptron                0.787855     0.968131\n",
       "DecisionTreeClassifier    0.786318     1.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = vectorize_all(train, test, dichotomy=2)\n",
    "dicho2_result_dict = fit_and_evaluate_all(classifiers, X_train, y_train, X_test, y_test)\n",
    "dicho2_result = pd.DataFrame.from_dict(dicho2_result_dict).transpose().sort_values('accur_test', ascending=False)\n",
    "dicho2_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third Dichotomy: F or T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultinomialNB...\n",
      "Training LogisticRegression...\n",
      "Training Perceptron...\n",
      "Training DecisionTreeClassifier...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accur_test</th>\n",
       "      <th>accur_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.772483</td>\n",
       "      <td>0.970979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.770177</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.721752</td>\n",
       "      <td>0.909140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.592621</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        accur_test  accur_train\n",
       "MultinomialNB             0.772483     0.970979\n",
       "LogisticRegression        0.770177     1.000000\n",
       "Perceptron                0.721752     0.909140\n",
       "DecisionTreeClassifier    0.592621     1.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = vectorize_all(train, test, dichotomy=3)\n",
    "dicho3_result_dict = fit_and_evaluate_all(classifiers, X_train, y_train, X_test, y_test)\n",
    "dicho3_result = pd.DataFrame.from_dict(dicho3_result_dict).transpose().sort_values('accur_test', ascending=False)\n",
    "dicho3_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourth Dichotomy: J or P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultinomialNB...\n",
      "Training LogisticRegression...\n",
      "Training Perceptron...\n",
      "Training DecisionTreeClassifier...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accur_test</th>\n",
       "      <th>accur_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.654112</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.652575</td>\n",
       "      <td>0.979251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perceptron</th>\n",
       "      <td>0.650269</td>\n",
       "      <td>0.941009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.556495</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        accur_test  accur_train\n",
       "LogisticRegression        0.654112     1.000000\n",
       "MultinomialNB             0.652575     0.979251\n",
       "Perceptron                0.650269     0.941009\n",
       "DecisionTreeClassifier    0.556495     1.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = vectorize_all(train, test, dichotomy=4)\n",
    "dicho4_result_dict = fit_and_evaluate_all(classifiers, X_train, y_train, X_test, y_test)\n",
    "dicho4_result = pd.DataFrame.from_dict(dicho4_result_dict).transpose().sort_values('accur_test', ascending=False)\n",
    "dicho4_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Assesment\n",
    "The Best model so far is the Logistic Regression. It outperforms the three other algorithms in each dichotomy. I would highly recommend against using the Kernelized SVM for this project since it was the worst performing algorithm for 3 out of 5 models and makes the process of running this notebook take about 25 minutes where it is usually about 2-3 minutes. For this reason, I omit the SVM from our results above. However, it will run if you uncomment the SVM from the \n",
    "\"Set Parameters for this notebook\" section near the beginning.\n",
    "\n",
    "### Confusion Matrix for Logistic Regression Model\n",
    "Here is the confusion matrix for the log regression model (personality words filtered out):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E</th>\n",
       "      <th>I</th>\n",
       "      <th>N</th>\n",
       "      <th>S</th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "      <th>J</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>79</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>21</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    E   I   N   S   F   T   J   P\n",
       "E  79  21   0   0   0   0   0   0\n",
       "I  21  79   0   0   0   0   0   0\n",
       "N   0   0  83  17   0   0   0   0\n",
       "S   0   0  17  83   0   0   0   0\n",
       "F   0   0   0   0  77  23   0   0\n",
       "T   0   0   0   0  23  77   0   0\n",
       "J   0   0   0   0   0   0  65  35\n",
       "P   0   0   0   0   0   0  35  65"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix published publicly\n",
    "url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vTUfeQEuInf0tpeOPeYa3onyEzou_tqtCWu7UpKOaSHPyNqcjPBgVKPe8OO'+ \\\n",
    "      'PaqzdFy7CuHxzm_0c8YN/pub?gid=0&single=true&output=csv'\n",
    "pd.read_csv(url, index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix for Logistic Regression Model\n",
    "Here is the confusion matrix for the log regression model (personality words not filtered out):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E</th>\n",
       "      <th>I</th>\n",
       "      <th>N</th>\n",
       "      <th>S</th>\n",
       "      <th>F</th>\n",
       "      <th>T</th>\n",
       "      <th>J</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>83</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>17</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    E   I   N   S   F   T   J   P\n",
       "E  83  17   0   0   0   0   0   0\n",
       "I  17  83   0   0   0   0   0   0\n",
       "N   0   0  86  14   0   0   0   0\n",
       "S   0   0  14  86   0   0   0   0\n",
       "F   0   0   0   0  81  19   0   0\n",
       "T   0   0   0   0  19  81   0   0\n",
       "J   0   0   0   0   0   0  71  29\n",
       "P   0   0   0   0   0   0  29  71"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix published publicly\n",
    "url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRP1tGYOS4z5U6KX1szj3HY_Q2y-u2iX-4ljhq9sFSvTmSMjp0LatjDp9E0'+ \\\n",
    "      'bBcw_ptpYXST2YYuAcOu/pub?gid=0&single=true&output=csv'\n",
    "pd.read_csv(url, index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do best on predicting the second dichotomy, S or N for a given user. We do worst on predicting the final dichotomy J or P.<br>\n",
    "You may also notice that filtering out personality words and accronyms has a negative effect on accuracy. However, I hypothesize that it would be best to keep filtering these personality words out because it will likely yield a model that is better suited to being used on more diverse discourse than just that on Personality Cafe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "I was actually surprised to see how well these models do, especially that the 16-way classifier acheives 38% accuracy even after filtering out personality type related words and accronymns I was not surprised, however, to see that there is a huge lift by using the 4 separate 2-way classifiers instead of the single one. It was interesting to note that leaving the personality type terms in the feature vector yielded better accuracy than leaving them out. Though I do believe that, unless we were building this model to predict personality type based on posts from somewhere like Personality Cafe alone, it would be best to leave them out since this should hopefully prevent the model from overfitting to this specific type of discourse alone.\n",
    "\n",
    "### Next Steps\n",
    "I have to thank Leo for suggesting a great way to mine for new data outside of Personality Cafe. Leo suggested that since there are numerous personality quizes on social media, it would be possible to find users who have taken an MBTI quiz through social media and to then extract their previous n posts for more data. This would be my next step since it could provide data from a much more well-rounded field of discourse. This would hopefully lead to a model that could better predict personality type based on other types of discourse.<br>\n",
    "Additionally, another next step would be to pass the result through a softmax layer to produce a probability. I think this would be a great way to make the model more interesting and useful to users. I imagine that you could have a \"Let ML predict your personality type, did it get it right?\" kind of application where users would submit their previous 50 posts or some other text and the model would return a prediction for each dichotomy. You could then ask the user to grade the model's performance giving us new data in the process!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_sparse_csr(filename, array):\n",
    "    # note that .npz extension is added automatically\n",
    "    np.savez(filename, data=array.data, indices=array.indices,\n",
    "             indptr=array.indptr, shape=array.shape)\n",
    "\n",
    "def save_y_array(filename, array):\n",
    "    array = [str(a) for a in array]\n",
    "    with open(filename, 'w') as writer:\n",
    "        writer.write('\\n'.join(array))\n",
    "\n",
    "save_sparse_csr('./data/X_train', X_train)\n",
    "save_sparse_csr('./data/X_test', X_test)\n",
    "# save_sparse_csr('X_dev', X_dev)\n",
    "\n",
    "save_y_array('./data/y_train.txt', y_train)\n",
    "save_y_array('./data/y_test.txt', y_test)\n",
    "# save_y_array('y_dev.txt', y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech_processing",
   "language": "python",
   "name": "speech_processing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
